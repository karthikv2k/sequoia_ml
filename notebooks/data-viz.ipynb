{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import normalize\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import math\n",
    "plt.rcdefaults()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_df(basePath):\n",
    "    from os import listdir\n",
    "    from os.path import isfile, join\n",
    "    onlyfiles = [ f for f in listdir(basePath) if isfile(join(basePath,f)) and f.endswith(\".csv\") ]\n",
    "    df_list = []\n",
    "    df = []\n",
    "    for f in onlyfiles:\n",
    "        print \"processing \" + basePath + f\n",
    "        df1 = pd.read_csv(basePath + f, index_col = \"loggingTime\",parse_dates=True, infer_datetime_format=True)\n",
    "        if len(df)==0:\n",
    "            df = df1\n",
    "        else:\n",
    "            df = df.append(df1)            \n",
    "        #df_list.append(df1)\n",
    "    #df = pd.concat(df_list)\n",
    "    #a_df = df[[\"accelerometerAccelerationX\",\"accelerometerAccelerationY\",\"accelerometerAccelerationZ\"]]\n",
    "    #a_df.plot(figsize=(50,10))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_windows(df):\n",
    "    gdf = df.groupby(pd.TimeGrouper('1s',closed='left'))\n",
    "    groups = [group for group in gdf]\n",
    "    windows = []\n",
    "    overlap = 3\n",
    "    for i in range(overlap-1,len(groups)):\n",
    "        name = groups[i][0]\n",
    "        windows.append(pd.concat([x[1] for x in groups[i-overlap+1:i+1]]))\n",
    "    return windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rotate_x(theta, point):\n",
    "    rx = np.array([[1, 0, 0],\n",
    "                   [0, math.cos(theta), -math.sin(theta)],\n",
    "                   [0, math.sin(theta), math.cos(theta)]])\n",
    "    return np.asmatrix(rx)*np.asmatrix(point)\n",
    "\n",
    "\n",
    "def rotate_y(theta, point):\n",
    "    ry = np.array([[math.cos(theta), 0, math.sin(theta)],\n",
    "                   [0, 1, 0],\n",
    "                   [-math.sin(theta), 0, math.cos(theta)]])\n",
    "    return np.asmatrix(ry)*np.asmatrix(point)\n",
    "\n",
    "def rotate_z(theta, point):\n",
    "    ry = np.array([[math.cos(theta), -math.sin(theta), 0],\n",
    "                   [math.sin(theta), math.cos(theta), 0],\n",
    "                   [0, 0, 1]])\n",
    "    return np.asmatrix(ry)*np.asmatrix(point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_features(df_list):\n",
    "    features_names = [\"avg_acc\", \"max_acc\", \"min_acc\", \"avg_gyro\", \"max_gyro\", \"min_gyro\", \"y\"]\n",
    "    f_map = {}\n",
    "    for fname in features_names:\n",
    "        f_map[fname] = []\n",
    "        \n",
    "    for df in df_list:\n",
    "        ndf = df[[\"state\"]]\n",
    "        ndf.loc[:,\"acc\"] = (df[[\"accelerometerAccelerationX\", \"accelerometerAccelerationY\", \"accelerometerAccelerationZ\"]]**2).sum(axis=1)\n",
    "        ndf.loc[:,\"gyro\"] = (df[[\"gyroRotationX\", \"gyroRotationY\", \"gyroRotationZ\"]]**2).sum(axis=1)    \n",
    "        agg = ndf.mean()\n",
    "        if np.isnan(agg[\"acc\"]):\n",
    "            continue\n",
    "        f_map[\"avg_acc\"].append(agg[\"acc\"])\n",
    "        f_map[\"avg_gyro\"].append(agg[\"gyro\"])\n",
    "\n",
    "        agg = ndf.max()\n",
    "        f_map[\"max_acc\"].append(agg[\"acc\"])   \n",
    "        f_map[\"max_gyro\"].append(agg[\"gyro\"])\n",
    "        f_map[\"y\"].append(agg[\"state\"]+0.1)\n",
    "\n",
    "        agg = ndf.min()\n",
    "        f_map[\"min_acc\"].append(agg[\"acc\"])    \n",
    "        f_map[\"min_gyro\"].append(agg[\"gyro\"])\n",
    "    return pd.DataFrame(data=f_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_map(f_map):\n",
    "    f, ax = plt.subplots(len(f_map), sharex=True,figsize=(10,len(f_map)*3))\n",
    "    for i,f in enumerate(f_map):\n",
    "        ax[i].plot(f_map[f])\n",
    "        ax[i].set_title(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "from sklearn import cross_validation\n",
    "from sklearn import svm\n",
    "import sklearn\n",
    "import pickle\n",
    "\n",
    "def split(df):\n",
    "    train_ratio = 0.5\n",
    "    N = len(df)\n",
    "    cols = [x for x in df.columns.get_values() if x!=\"y\"]\n",
    "    X = df[cols].values\n",
    "    Y = df[\"y\"].values\n",
    "    X_train = X[:int(train_ratio*N)]\n",
    "    X_test = X[int(train_ratio*N):]\n",
    "    Y_train = Y[:int(train_ratio*N)]    \n",
    "    Y_test = Y[int(train_ratio*N):]\n",
    "    return [X, Y, X_train, Y_train, X_test, Y_test]\n",
    "    \n",
    "def scale(X):\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    pickle.dump(scaler, open(\"scaler.pickle\", 'w'))\n",
    "    return scaler, X_scaled\n",
    "\n",
    "def train(X,Y):\n",
    "    clf = linear_model.LogisticRegression(C=1e5)\n",
    "    #clf = svm.SVC(kernel='poly',degree=3)\n",
    "    clf.fit(X, Y)\n",
    "    pickle.dump(clf, open(\"model.pickle\", 'w'))\n",
    "    return clf\n",
    "    \n",
    "def predict(scaler, clf, X):\n",
    "    X_test_scaled = scaler.transform(X)\n",
    "    return clf.predict(X_test_scaled)\n",
    "    #return sklearn.cross_validation.cross_val_predict(clf, X_scaled, Y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_svd(df):\n",
    "    from sklearn.decomposition import TruncatedSVD\n",
    "    svd = TruncatedSVD(n_components=2)\n",
    "    X_svd = svd.fit_transform(df)\n",
    "    return X_svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "basePath = \"/Users/karthik/Documents/workspace/sequoia-ml/data/\"\n",
    "columns = [\"accelerometerAccelerationX\", \"accelerometerAccelerationY\", \n",
    "           \"accelerometerAccelerationZ\", \"gyroRotationX\", \"gyroRotationY\", \"gyroRotationZ\",\n",
    "          \"state\"]\n",
    "df = load_df(basePath)\n",
    "df = df[columns]\n",
    "df_windowed = get_windows(df)\n",
    "f_df = extract_features(df_windowed)\n",
    "\n",
    "f_df = f_df[f_df[\"y\"]<4.1]\n",
    "f_df.loc[(f_df[\"y\"]==2.1) & (f_df['max_acc']<20), 'y'] = 0.1\n",
    "\n",
    "[X, Y, X_train, Y_train, X_test, Y_test] = split(f_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[x.shape for x in [X, Y, X_train, Y_train, X_test, Y_test]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scaler, X_train_scaled = scale(X_train)\n",
    "X_scaled = scaler.transform(X)\n",
    "clf = train(X_scaled, Y)\n",
    "y_predict = predict(scaler, clf, X_scaled)\n",
    "\n",
    "ad_clf = anomaly_detect(X_scaled)\n",
    "ad_score = ad_clf.decision_function(X_scaled).ravel()\n",
    "ad_predict = ad_clf.predict(X_scaled)\n",
    "\n",
    "\n",
    "df_viz = f_df.copy()\n",
    "df_viz.loc[:,'y_predict'] = pd.Series(data=y_predict, index=f_df.index)\n",
    "df_viz.loc[:,'ad_score'] = pd.Series(data=ad_score, index=f_df.index)\n",
    "df_viz.loc[:,'ad_predict'] = pd.Series(data=ad_predict, index=f_df.index)\n",
    "tmp1 = df_viz.plot(subplots=True, figsize=(10,df_viz.columns.size*3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##outlier and novelty detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "def anomaly_detect(df):\n",
    "    outliers_fraction = 0.005\n",
    "    clf = svm.OneClassSVM(nu=0.95 * outliers_fraction + 0.05, kernel=\"rbf\", gamma=0.1)\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    X = scaler.fit_transform(df)\n",
    "    clf.fit(X)\n",
    "    pickle.dump(clf, open(\"ad.pickle\", 'w'))\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = anomaly_detect(X_scaled)\n",
    "plt.plot(clf.predict(X_scaled)+0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(clf.decision_function(X_scaled).ravel())\n",
    "print len(y_predict)\n",
    "print len(f_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svd = plot_svd(f_df)\n",
    "fig = plt.figure(figsize=(20,20))\n",
    "plt.scatter(svd[:,0],svd[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(clf.predict_log_proba(X_scaled)[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
